# Desafio MBA Engenharia de Software com IA - Full Cycle

Sistema RAG (Retrieval-Augmented Generation) para ingestÃ£o e busca de documentos PDF usando PostgreSQL com pgvector e OpenAI.

## ğŸ“‹ PrÃ©-requisitos

- Docker e Docker Compose instalados
- Python 3.11+
- Chave de API da OpenAI
- Documento PDF para ingestÃ£o (jÃ¡ incluÃ­do: `document.pdf`)

## ğŸš€ Como Executar

### 1. Subir o Docker (PostgreSQL + pgvector)

Primeiro, inicie o banco de dados PostgreSQL com suporte a pgvector:

```bash
docker compose up -d
```

Este comando irÃ¡:
- Iniciar um container PostgreSQL 17 com pgvector
- Criar o banco de dados `rag`
- Configurar o usuÃ¡rio `postgres` com senha `postgres`
- Expor a porta `5432`
- Executar automaticamente a extensÃ£o pgvector

**Verificar se estÃ¡ funcionando:**
```bash
docker compose ps
```

VocÃª deve ver os containers `postgres_rag` e `bootstrap_vector_ext` rodando.

### 2. Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```bash
# OpenAI Configuration
OPENAI_API_KEY=sua_chave_api_aqui
OPENAI_MODEL=text-embedding-3-small

# Database Configuration
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/rag
PG_VECTOR_COLLECTION_NAME=documentos

# PDF Configuration
PDF_PATH=document.pdf
```

**Importante:** Substitua `sua_chave_api_aqui` pela sua chave real da OpenAI.

### 3. Configurar Ambiente Python

Crie e ative um ambiente virtual:

```bash
python -m venv venv
source venv/bin/activate  # No Windows: venv\Scripts\activate
```

Instale as dependÃªncias:

```bash
pip install -r requirements.txt
```

### 4. IngestÃ£o dos Dados

Execute o script de ingestÃ£o para processar o documento PDF:

```bash
python src/ingest.py
```

**O que acontece durante a ingestÃ£o:**
- O PDF Ã© carregado e dividido em chunks de 1000 caracteres com overlap de 150
- Cada chunk Ã© convertido em embedding usando o modelo `text-embedding-3-small`
- Os embeddings sÃ£o armazenados no PostgreSQL usando pgvector
- VocÃª verÃ¡ a mensagem: "âœ… IngestÃ£o concluÃ­da com sucesso! X documentos foram processados"

**Troubleshooting da ingestÃ£o:**
- Verifique se o arquivo `document.pdf` existe na raiz do projeto
- Confirme se as variÃ¡veis de ambiente estÃ£o configuradas corretamente
- Certifique-se de que o Docker estÃ¡ rodando e o banco estÃ¡ acessÃ­vel

### 5. Usar o Chat

ApÃ³s a ingestÃ£o bem-sucedida, vocÃª pode fazer perguntas sobre o documento:

```bash
python src/chat.py
```

**Como usar o chat:**
1. Execute o comando acima
2. Digite sua pergunta quando solicitado
3. O sistema irÃ¡:
   - Buscar os chunks mais relevantes do documento
   - Usar o GPT-5-mini para gerar uma resposta baseada no contexto
   - Responder apenas com informaÃ§Ãµes presentes no documento

**Exemplo de uso:**
```
PERGUNTA: Qual Ã© o tema principal do documento?
RESPOSTA: [Resposta baseada no conteÃºdo do PDF]
```

## ğŸ”§ Arquitetura do Sistema

### Componentes Principais:

1. **PostgreSQL + pgvector**: Armazena embeddings vetoriais dos documentos
2. **OpenAI Embeddings**: Converte texto em vetores para busca semÃ¢ntica
3. **LangChain**: Framework para processamento de documentos e RAG
4. **PyPDF**: Carregamento e processamento de PDFs

### Fluxo de Funcionamento:

1. **IngestÃ£o**: PDF â†’ Chunks â†’ Embeddings â†’ PostgreSQL
2. **Busca**: Pergunta â†’ Embedding â†’ Similaridade â†’ Contexto
3. **GeraÃ§Ã£o**: Contexto + Pergunta â†’ GPT â†’ Resposta

## ğŸ“ Estrutura do Projeto

```
mba-ia-desafio-ingestao-busca/
â”œâ”€â”€ docker compose.yml          # ConfiguraÃ§Ã£o do PostgreSQL + pgvector
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ document.pdf               # Documento para ingestÃ£o
â”œâ”€â”€ .env                       # VariÃ¡veis de ambiente (criar)
â”œâ”€â”€ README.md                  # Este arquivo
â””â”€â”€ src/
    â”œâ”€â”€ ingest.py              # Script de ingestÃ£o
    â”œâ”€â”€ search.py              # LÃ³gica de busca e RAG
    â””â”€â”€ chat.py                # Interface de chat
```

## ğŸ› ï¸ Troubleshooting

### Problemas Comuns:

**Erro de conexÃ£o com banco:**
- Verifique se o Docker estÃ¡ rodando: `docker compose ps`
- Confirme se a porta 5432 estÃ¡ livre
- Teste a conexÃ£o: `psql postgresql://postgres:postgres@localhost:5432/rag`

**Erro de API OpenAI:**
- Verifique se a chave API estÃ¡ correta no `.env`
- Confirme se tem crÃ©ditos suficientes na conta OpenAI

**Erro de ingestÃ£o:**
- Verifique se o arquivo `document.pdf` existe
- Confirme se todas as variÃ¡veis de ambiente estÃ£o definidas

**Erro de mÃ³dulos Python:**
- Ative o ambiente virtual: `source venv/bin/activate`
- Reinstale as dependÃªncias: `pip install -r requirements.txt`

## ğŸ§¹ Limpeza

Para parar e remover os containers:

```bash
docker compose down -v
```

Para remover completamente os dados:

```bash
docker compose down -v --rmi all
```

## ğŸ“ Notas Importantes

- O sistema responde apenas com base no conteÃºdo do documento ingerido
- Se uma pergunta nÃ£o estiver no contexto, o sistema responderÃ¡: "NÃ£o tenho informaÃ§Ãµes necessÃ¡rias para responder sua pergunta"
- O modelo usado para embeddings Ã© `text-embedding-3-small` (padrÃ£o) ou configurÃ¡vel via `OPENAI_MODEL`
- O modelo usado para geraÃ§Ã£o de respostas Ã© `gpt-5-mini`
- Os chunks tÃªm tamanho de 1000 caracteres com overlap de 150 para melhor contexto